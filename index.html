<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>speech-polyfill sample</title>
    <style>
        html, body{
            font-family: "Lucida Console", Monaco, monospace;
            background: #333333;
            color: #cccccc;
        }

        span{
            color: #666666;
        }

        .intermediate{
            font-style: italic;
        }

        .final{
            color: #cccccc;
            font-style: unset;
        }
    </style>
</head>

<body>
    <span>Just talk ;-)</span>
    <br>
    <br>
    <script src="node_modules/speech-polyfill/dist/speech-polyfill.js"></script>
    <script>

        window.addEventListener('load', () => {
            let shouldContinue = true;
            const recognizer = new SpeechRecognition('840815e255664714a82d948ab97d132a');
            recognizer.interimResults = true;
            recognizer.continuous = false;
            recognizer.maxAlternatives = 6;

            let elem = document.createElement('span');
            document.body.appendChild(elem);

            recognizer.onresult = e => {
                console.log('result', e)
                elem.innerText = e.results[0][0].transcript;
                elem.className = "intermediate";

                shouldContinue = !elem.innerText.toLowerCase().indexOf('stop') >= 0;

                if (e.results[0].isFinal) {
                    elem.innerText = elem.innerText + " ";
                    elem.className = "final"
                    elem = document.createElement('span');
                    document.body.appendChild(elem);
                }
            };

            recognizer.onerror = (event) => console.log('error', event);
            recognizer.onnomatch = (event) => console.log('nomatch', event);

            recognizer.onaudiostart = (event) => console.log('audiostart', event);
            recognizer.onaudioend = (event) => console.log('audioend', event);

            recognizer.onend = (event) => {
                recognizer.stop();
                console.log('end', event);
                if(shouldContinue){
                    recognizer.start();
                }
            }
            recognizer.onstart = (event) => console.log('start', event);

            recognizer.onsoundstart = (event) => console.log('soundstart', event);
            recognizer.onsoundend = (event) => console.log('soundend', event);

            recognizer.onspeechstart = (event) => console.log('speechstart', event);
            recognizer.onspeechend = (event) => console.log('speechend', event);

            recognizer.start();
        });
    </script>
    <script type="text/javascript">
        var appInsights=window.appInsights||function(config){
          function i(config){t[config]=function(){var i=arguments;t.queue.push(function(){t[config].apply(t,i)})}}var t={config:config},u=document,e=window,o="script",s="AuthenticatedUserContext",h="start",c="stop",l="Track",a=l+"Event",v=l+"Page",y=u.createElement(o),r,f;y.src=config.url||"https://az416426.vo.msecnd.net/scripts/a/ai.0.js";u.getElementsByTagName(o)[0].parentNode.appendChild(y);try{t.cookie=u.cookie}catch(p){}for(t.queue=[],t.version="1.0",r=["Event","Exception","Metric","PageView","Trace","Dependency"];r.length;)i("track"+r.pop());return i("set"+s),i("clear"+s),i(h+a),i(c+a),i(h+v),i(c+v),i("flush"),config.disableExceptionTracking||(r="onerror",i("_"+r),f=e[r],e[r]=function(config,i,u,e,o){var s=f&&f(config,i,u,e,o);return s!==!0&&t["_"+r](config,i,u,e,o),s}),t
          }({
              instrumentationKey:"329dd149-57d8-492e-8554-1f26f491a7a9"
          });
             
          window.appInsights=appInsights;
          appInsights.trackPageView();
      </script>
</body>

</html>